{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world.csv\n",
      "eucouncil.csv\n",
      "README.md\n",
      "abcwnn.csv\n",
      "nytimesopinionart.csv\n",
      "yoga.csv\n",
      "daringplanet.csv\n",
      "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "hidden_shots_.csv\n",
      "talentmoves.csv\n",
      "nature.research.csv\n",
      "healthyfoodvideos.csv\n",
      "commonwealth_sec.csv\n",
      "healthy.foodyss.csv\n",
      "wanderlustfest.csv\n",
      "afpsport.csv\n",
      "ageofempires.csv\n",
      "ptiphotos.csv\n",
      "ageofempiresgame.csv\n",
      "mitpics.csv\n",
      "viceindia.csv\n",
      "sciencechannel.csv\n",
      "voxdotcom.csv\n",
      "life.csv\n",
      "scroll_in.csv\n",
      "educationaboutearth.csv\n",
      "oxford_uni.csv\n",
      "merge.py\n",
      "nature_africa.csv\n",
      "aamaadmiparty.csv\n",
      "pbsnature.csv\n",
      "2038\n",
      "2038\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir('../data/insta_non_mentalhealth/'):\n",
    "    print(file)\n",
    "    if file[-3:] == \"csv\":\n",
    "        try:\n",
    "#             print('True')\n",
    "            path = \"../data/insta_non_mentalhealth/\"+str(file)\n",
    "            df = pd.read_csv(path)\n",
    "            data.append(df)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "df = pd.concat(data, axis=0, ignore_index=True)\n",
    "df.head()\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "#https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',str(text))\n",
    "\n",
    "# appending first 25 comments into one big comment\n",
    "def appendComments(comment):\n",
    "  lst = comment.split(\"|\")\n",
    "  final_comment = \"\"\n",
    "  for idx,entry in enumerate(lst):\n",
    "    if idx == 25:\n",
    "      break\n",
    "    entry.strip()\n",
    "    final_comment +=  entry + \" \"\n",
    "  return final_comment\n",
    "\n",
    "def cleanComment(comment):\n",
    "  deEmojified_comment = deEmojify(comment)\n",
    "  return appendComments(deEmojified_comment)\n",
    "\n",
    "df[\"comments\"] = df[\"comments\"].apply(lambda x:cleanComment(x))\n",
    "\n",
    "#combining comments and actual post\n",
    "df[\"text_with_comments\"] = df[\"text\"]+ \" \"+ df[\"comments\"]\n",
    "\n",
    "# removing punctuations,and converting upper to lower case letters\n",
    "\n",
    "punctuations = string.punctuation\n",
    "table = punctuations.maketrans(punctuations+string.ascii_uppercase,\n",
    "                               \" \"*len(punctuations)+string.ascii_lowercase,)\n",
    "\n",
    "def cleanPosts(sentence):\n",
    "  sentence.strip()\n",
    "  sen = sentence.translate(table)\n",
    "  return sen\n",
    "\n",
    "def cleanHashTags(sentence):\n",
    "  sentence.strip()\n",
    "  sen = sentence.translate(table)\n",
    "  return \"$start \" + sen + \" end$\"\n",
    "\n",
    "post_df = df[\"text_with_comments\"].apply(lambda w:cleanPosts(str(w)))\n",
    "hashtag_df = df[\"hashtags\"].apply(lambda w: cleanHashTags(str(w)))\n",
    "\n",
    "#### Likes\n",
    "\n",
    "# here we only consider hashtags that are appearing atleast 10 times\n",
    "def count_hashtag_likes(all_posts_hashtags,all_posts_likes):\n",
    "  hashtag_likesCount = defaultdict(int)\n",
    "  hashtagAppearanceCount = defaultdict(int)\n",
    "  hashtag_first10_likesCount = defaultdict(int)\n",
    "  for hashtags,count in zip(all_posts_hashtags,all_posts_likes):\n",
    "    hashtags = str(hashtags).split()\n",
    "    for hashtag in hashtags:\n",
    "      hashtagAppearanceCount[hashtag] += 1\n",
    "      if hashtagAppearanceCount[hashtag] >= 10:\n",
    "        if hashtag not in hashtag_likesCount:\n",
    "          hashtag_likesCount[hashtag] = hashtag_first10_likesCount[hashtag] + count\n",
    "        hashtag_likesCount[hashtag] += count\n",
    "        continue\n",
    "      hashtag_first10_likesCount[hashtag] += count      \n",
    "  return hashtag_likesCount\n",
    "\n",
    "hashtag_likesCount = count_hashtag_likes(hashtag_df.values.tolist(),df[\"likes\"].values.tolist())\n",
    "print(len(hashtag_likesCount))\n",
    "\n",
    "#  list of hashtags appearing atleast 10 times\n",
    "frequent_hashtags = hashtag_likesCount.keys()\n",
    "print(len(frequent_hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/medha/anaconda3/envs/transformers/lib/python3.8/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /home/medha/anaconda3/envs/transformers/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
